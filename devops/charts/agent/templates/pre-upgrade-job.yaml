# !!! this job only used for upgrade devops from 1.1.0 to 1.1.1(4.1.2)
# TODO: delete this job in version > 1.1.1

apiVersion: v1
kind: ServiceAccount
metadata:
  name: {{ .Release.Name }}-pre-upgrade
  namespace: {{ .Release.Namespace }}
  annotations:
    helm.sh/hook: pre-upgrade
    helm.sh/hook-weight: "0"
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded

---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: {{ .Release.Name }}-pre-upgrade
  namespace: {{ .Release.Namespace }}
  annotations:
    helm.sh/hook: pre-upgrade
    helm.sh/hook-weight: "0"
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
rules:
  - apiGroups:
      - ""
    resources:
      - configmaps
      - pods
      - pods/exec
    verbs:
      - "*"
  - apiGroups:
      - kubesphere.io
    resources:
      - installplans
    verbs:
      - "*"

---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: {{ .Release.Name }}-pre-upgrade
  namespace: {{ .Release.Namespace }}
  annotations:
    helm.sh/hook: pre-upgrade
    helm.sh/hook-weight: "1"
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
subjects:
  - kind: ServiceAccount
    name: {{ .Release.Name }}-pre-upgrade
    namespace: {{ .Release.Namespace }}
roleRef:
  kind: Role
  name: {{ .Release.Name }}-pre-upgrade
  apiGroup: rbac.authorization.k8s.io

---
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Release.Name }}-pre-upgrade
  annotations:
    helm.sh/hook: pre-upgrade
    helm.sh/hook-weight: "2"
spec:
  ttlSecondsAfterFinished: 3600
  template:
    spec:
      restartPolicy: Never
      serviceAccountName: {{ .Release.Name }}-pre-upgrade
      {{- with .Values.global.imagePullSecrets }}
      imagePullSecrets:
      {{- toYaml . | nindent 8 }}
      {{- end }}
      containers:
      - name: pre-upgrade-job
        image: '{{ default "docker.io" .Values.global.imageRegistry }}/kubesphere/kubectl:v1.27.4'
        command: ["/bin/bash"]
        env:
          - name: DEVOPS_NAMESPACE
            value: "{{ .Values.global.namespace }}"
        args:
          - "-c"
          - |
            # add kubeconfigEnabled: true to installplan
            if kubectl get installplans.kubesphere.io devops &>/dev/null; then
              if kubectl get installplans.kubesphere.io devops -o yaml|grep 'kubeconfigEnabled: true' &>/dev/null; then
                echo "the kubeconfigEnabled exist, ignore"
              else
                echo "add 'kubeconfigEnabled: true' to installplan devops.."
                kubectl get installplans.kubesphere.io devops -o yaml|sed 's/      jenkins:/      jenkins: \n        kubeconfigEnabled: true/'|kubectl apply -f -
              fi
            fi

            # replace value of fullNameFieldName and userNameField
            # delete kubesphereAuth configuration
            if kubectl -n ${DEVOPS_NAMESPACE} get cm jenkins-casc-config -o yaml | grep -E "fullNameFieldName: name|userNameField: name" &>/dev/null; then
              echo "update fullNameFieldName and userNameField in configmap jenkins-casc-config.."
              kubectl -n ${DEVOPS_NAMESPACE} get cm jenkins-casc-config -o yaml | sed -e '/kubespheretokenauthglobalconfiguration:/{N;N;N;N;d;}' | sed -e 's/fullNameFieldName: name/fullNameFieldName: url/' | sed -e 's/userNameField: name/userNameField: preferred_username/' | kubectl apply -f -
            else
              echo "the fullNameFieldName and userNameField aren't 'name', ignore"
            fi

            # delete plugin kubesphere-token-auth
            echo "delete plugin kubesphere-token-auth.."
            kubectl -n ${DEVOPS_NAMESPACE} -c devops-jenkins exec -it $(kubectl -n ${DEVOPS_NAMESPACE} get pod -l app=devops-jenkins --no-headers=true -o custom-columns=:.metadata.name) -- rm -rf /var/jenkins_home/plugins/kubesphere-token-auth /var/jenkins_home/plugins/kubesphere-token-auth.jpi
